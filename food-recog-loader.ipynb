{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Datasets\n\nAll datasets are initially downloaded from [aicrowd](), and then uploaded to Kaggle to have them available there. This saves a lot of time on reloading the data when opening the notebook or running a new run. \n\nImport datasets from Kaggle directory of jaflaten \nthe datasets are \n- food-testing\n- food-validation\n- food-training\n","metadata":{}},{"cell_type":"markdown","source":"Optional: Checking if the files are in place","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/food-training\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing dependencies\nImporting all the dependencies needed for training the model","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *\nimport numpy as np\nimport pandas as pd\nimport random\nfrom PIL import Image\nimport os\nimport json\nfrom pathlib import Path\nfrom fastai.metrics import Precision, Recall, accuracy\nimport timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining paths for datasets\nDefining the paths for the training and validation set images.","metadata":{}},{"cell_type":"code","source":"#define paths\n\npath_validation = Path(\"/kaggle/input/food-validation/images/\")\npath_training = Path(\"/kaggle/input/food-training/images/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the metadata \nThe annotations.json file is a structure of information which includes a image_id and a category_id which are important when labelling the data. \n\nHere I load the metadata annotations.json for both training and validation set and creating a mapping between the category id and the name \n","metadata":{}},{"cell_type":"code","source":"# Load annotations file\ntrain_annotations_path = Path(\"/kaggle/input/food-training/annotations.json\")\nval_annotations_path = Path(\"/kaggle/input/food-validation/annotations.json\")\n\nwith open(train_annotations_path) as f:\n    train_annotations = json.load(f)\n    \nwith open(val_annotations_path) as f:\n    val_annotations = json.load(f)    \n\n# Create a dictionary mapping category IDs to their names\ncategories = {}\nfor category in train_annotations[\"categories\"]:\n    categories[category[\"id\"]] = category[\"name\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThe annotations.json data is loaded and added to a Pandas Dataframe for each dataset, one for training and one for validation.\n","metadata":{}},{"cell_type":"code","source":"with open(train_annotations_path) as json_data:\n    data = json.load(json_data)\n    df_train_annotations = pd.DataFrame(data['annotations'])\n    \nwith open(val_annotations_path) as json_data:\n    data = json.load(json_data)\n    df_val_annotations = pd.DataFrame(data['annotations'])    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the output from each dataframe to verify it looks reasonable","metadata":{}},{"cell_type":"code","source":"df_train_annotations.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val_annotations.head(2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### merging datasets\nHere the training and validation datasets are merged into one make it easier to use when we will create a ImageDataLoader later.","metadata":{}},{"cell_type":"code","source":"df_annotations = pd.concat([df_train_annotations, df_val_annotations])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_annotations.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Labelling the data\n\nTo label each image with the correct label based onthe image id I needed to iterate the annotations file and find the images with the corresponding image id similar to the name of the image file. So this function can take a given image name and return the label that should be set to that image. ","metadata":{}},{"cell_type":"code","source":"\n# Define the get_label function\ndef get_label(image_filename):\n    image_id = int(Path(image_filename).stem.lstrip(\"0\"))\n    return categories[df_annotations.loc[df_annotations['image_id'] == image_id]['category_id'].values[0]]\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testing the get_lable function to verify that we get labels based on a pre-picked image. ","metadata":{}},{"cell_type":"code","source":"get_label(\"059339.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_label(\"149022.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modifying the dataframe\nCreating a new dataframe containing two columns. One for the image name full path including the filename. For instance ```/kaggle/input/food-training/images/059339.jpg```\n\nAnd one column to determine if the image is from the test or the validation set by setting the ```is_val``` to either False or True. This will be True for the validation data, and false otherwise.\n\nAt the end the two dataframes are merged together to one dataframe. ","metadata":{}},{"cell_type":"code","source":"df_train = pd.DataFrame(list(path_training.ls()), columns=[\"img\"])\ndf_val = pd.DataFrame(list(path_validation.ls()), columns=[\"img\"])\n\ndf_train[\"is_val\"] = False\ndf_val[\"is_val\"] = True\ndf = pd.concat([df_train, df_val])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Verifying dataframe content with manual inspection","metadata":{}},{"cell_type":"code","source":"df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding the labels\nThe last modification to the dataframe is to add another column for the label to each image, this is so the model can know what is correct and wrong when being trained. To add the model we can use the get_label function that was defined earlier and do this for every image in the dataframe","metadata":{}},{"cell_type":"code","source":"df['label'] = df['img'].apply(get_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating a ImageDataLoader\n\nTo create the ImageDataLoader we want to create it from the dataframe that was stitched together above. The images are being resized and scaled. The labels are set using the get_label function defined above. ","metadata":{}},{"cell_type":"code","source":"dls = ImageDataLoaders.from_df(df, label_col=2, valid_col=1, path=\"/\",\n                                item_tfms=Resize(192, method='squish'),\n                                batch_tfms=aug_transforms(size=128, min_scale=0.75),\n                                label_func=get_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing resize crop \n#dls.train = dls.train.new(\n#    item_tfms=RandomResizedCrop(128, min_scale=0.5),\n#    batch_tfms=aug_transforms(size=128, min_scale=0.75)\n#)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking out a small sample of the images to see what they look like and that they are labeled\n","metadata":{}},{"cell_type":"code","source":"dls.show_batch(max_n=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set a architecture to use","metadata":{}},{"cell_type":"code","source":"architecture = 'convnext_large_in22ft1k'\n#architecture = 'convnext_small_in22k'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Metrics and creating a vision learner\n\nWe want to have average precision, average recall and accuracy as our metrics. The AP and AR are to be able to compare the model to the leaderboards at [aicrowd](https://www.aicrowd.com/challenges/food-recognition-benchmark-2022/leaderboards). Accuracy will be a useful metric to easily see how well the model performs on the validation set. \n\nThese are used as parameters to the vision_learner when creating a learner. We also specify the architecture to use, the DataLoaders and that we want to use a pretrained model. The last parameter will significantly help us achieve proper results when leveraging a model that has already been trained on a large dataset. ","metadata":{}},{"cell_type":"code","source":"average_precision = Precision(average='macro', pos_label=1)\naverage_recall = Recall(average='macro', pos_label=1)\nlearner = vision_learner(dls, architecture, metrics=[accuracy, average_precision, average_recall], pretrained=True).to_fp16()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#learner = vision_learner(dls, resnet34, metrics=accuracy)\n#learner = vision_learner(dls, 'convnext_small_in22k', metrics=[ap, ar]).to_fp16()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Find learning rate\nFind the optimal learning rate for the model and use it when fine tuning","metadata":{}},{"cell_type":"code","source":"lr = learner.lr_find(suggest_funcs=(minimum, steep, valley), show_plot=True)\nbase_lr = (lr.valley + lr.steep)/2\nprint(base_lr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learner.fine_tune(5, base_lr=base_lr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Export the model\nExporting the model to a file to be used in a application. \n","metadata":{}},{"cell_type":"code","source":"learner.export(fname = '/kaggle/working/foodmodel.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"?learner.export","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}